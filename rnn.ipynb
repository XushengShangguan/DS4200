{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxbavS6L7F58hEpDMIBHcX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e463f042867248c1ad7d329e5c3f7643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_391eb25d6233410395467791a1287d0c",
              "IPY_MODEL_c20a4054d2b145349952ddce0c087411",
              "IPY_MODEL_6cc343281799421e928a3bb832f3682d"
            ],
            "layout": "IPY_MODEL_f58a8640c0ac40caa24a3122cc1d05a0"
          }
        },
        "391eb25d6233410395467791a1287d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e519b4b4694559827e7cf033167b39",
            "placeholder": "​",
            "style": "IPY_MODEL_3ffae624849247ce895abdf64414423e",
            "value": "Epoch 1:   6%"
          }
        },
        "c20a4054d2b145349952ddce0c087411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b910e4e7b8c4a208cfa23238901dce7",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b060c82daa8412f88109800d343a2bb",
            "value": 555
          }
        },
        "6cc343281799421e928a3bb832f3682d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b2d89f94eea4b6290b7ea79920885d5",
            "placeholder": "​",
            "style": "IPY_MODEL_84fab42bb1c744ad9ac22bb9be680057",
            "value": " 555/10000 [00:27&lt;08:43, 18.03step/s, acc=0.284, loss=3.819]"
          }
        },
        "f58a8640c0ac40caa24a3122cc1d05a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e519b4b4694559827e7cf033167b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffae624849247ce895abdf64414423e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b910e4e7b8c4a208cfa23238901dce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b060c82daa8412f88109800d343a2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b2d89f94eea4b6290b7ea79920885d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fab42bb1c744ad9ac22bb9be680057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XushengShangguan/DS4200/blob/main/rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uao0PX3UW0nS",
        "outputId": "9013f5ef-be11-4c06-e16b-c8b321ae8d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS-4120-Project-Repo'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NeyoNought47/CS-4120-Project-Repo.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4fljcG-TF0H",
        "outputId": "eba220c3-5df1-4c02-8c9d-f2d2937af829"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_path = '/content/drive/My Drive/clean'\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    print(os.listdir(data_path))\n",
        "    print(\"The file exists\")\n",
        "else:\n",
        "    print(f\"{data_path} does not exist\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTnJaK4WTYx3",
        "outputId": "f1e43adc-ef55-423c-fada-a5950507d857"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.DS_Store', 'es-SV', 'es-PE', 'es-NI', 'es-DO', 'es-EC', 'es-PA', 'es-PR', 'es-UY', 'es-CO', 'es-CR', 'es-VE', 'es-AR', 'es-HN', 'es-CL', 'std_es']\n",
            "The file exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "region_data = {}\n",
        "\n",
        "if os.path.exists(data_path):\n",
        "    sub_folders = sorted(os.listdir(data_path))\n",
        "\n",
        "    for folder_name in sub_folders:\n",
        "        folder_full_path = os.path.join(data_path, folder_name)\n",
        "\n",
        "        if os.path.isdir(folder_full_path) and folder_name.startswith('es-'):\n",
        "            path_en = os.path.join(folder_full_path, 'all.en')\n",
        "            path_es = os.path.join(folder_full_path, 'all.es')\n",
        "\n",
        "            if os.path.exists(path_en) and os.path.exists(path_es):\n",
        "                with open(path_en, 'r', encoding='utf-8') as f:\n",
        "                    lines_en = f.read().strip().split('\\n')\n",
        "                with open(path_es, 'r', encoding='utf-8') as f:\n",
        "                    lines_es = f.read().strip().split('\\n')\n",
        "\n",
        "                current_pairs = []\n",
        "                if len(lines_en) == len(lines_es):\n",
        "                    for en, es in zip(lines_en, lines_es):\n",
        "                        if en.strip() and es.strip():\n",
        "                            current_pairs.append([en.strip(), es.strip()])\n",
        "\n",
        "                    region_data[folder_name] = current_pairs\n",
        "\n",
        "\n",
        "print(\"regions:\", list(region_data.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZSzQqeNU3wF",
        "outputId": "9c609d6d-7300-4d2b-fd60-88a2cb07ca59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "regions: ['es-AR', 'es-CL', 'es-CO', 'es-CR', 'es-DO', 'es-EC', 'es-HN', 'es-NI', 'es-PA', 'es-PE', 'es-PR', 'es-SV', 'es-UY', 'es-VE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 20\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    s = re.sub(r\"([.!?¿¡,])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-ZáéíóúñÁÉÍÓÚÑ.!?¿¡,]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "           len(p[1].split(' ')) < MAX_LENGTH"
      ],
      "metadata": {
        "id": "vKWsJP88YL4R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY8AcbSfZ3RS",
        "outputId": "b944ad02-aaf2-45b8-e7e5-771c383f06c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "m8IZE9UmajhO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "AqVuSPfPatU2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(encoder, decoder, validation_pairs, input_lang, output_lang, criterion):\n",
        "    total_loss = 0\n",
        "    total_correct_tokens = 0\n",
        "    total_steps = len(validation_pairs)\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for pair in validation_pairs:\n",
        "            input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "            target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "\n",
        "            input_length = input_tensor.size(0)\n",
        "            target_length = target_tensor.size(0)\n",
        "\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "            encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
        "\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "                encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden, _ = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "                loss = criterion(decoder_output, target_tensor[di])\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                if topi.item() == target_tensor[di].item():\n",
        "                    total_correct_tokens += 1\n",
        "\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "                if decoder_input.item() == EOS_token:\n",
        "                    break\n",
        "\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    avg_loss = total_loss / (total_steps * target_length)\n",
        "    avg_acc = total_correct_tokens / (total_steps * target_length)\n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "7IpbdsSyexIm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def train_step(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "    correct_tokens = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < 0.5 else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == target_tensor[di].item():\n",
        "                correct_tokens += 1\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di] # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == target_tensor[di].item():\n",
        "                correct_tokens += 1\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length, correct_tokens / target_length"
      ],
      "metadata": {
        "id": "xAIUuDKPhPGB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train_specific_region(region_name, n_epochs=5, learning_rate=0.001):\n",
        "\n",
        "    if region_name not in region_data:\n",
        "        print(f\"Error: region is not in the list\")\n",
        "\n",
        "    raw_pairs = region_data[region_name]\n",
        "\n",
        "    input_lang = Lang(\"eng\")\n",
        "    output_lang = Lang(\"spa\")\n",
        "\n",
        "    clean_pairs = []\n",
        "    for en, es in raw_pairs:\n",
        "        clean_en = normalizeString(en)\n",
        "        clean_es = normalizeString(es)\n",
        "\n",
        "        if len(clean_en.split()) < MAX_LENGTH and len(clean_es.split()) < MAX_LENGTH:\n",
        "            clean_pairs.append([clean_en, clean_es])\n",
        "            input_lang.addSentence(clean_en)\n",
        "            output_lang.addSentence(clean_es)\n",
        "\n",
        "    random.shuffle(clean_pairs)\n",
        "    val_split = int(len(clean_pairs) * 0.8)\n",
        "    train_pairs_local = clean_pairs[:val_split]\n",
        "    val_pairs_local = clean_pairs[val_split:]\n",
        "\n",
        "    hidden_size = 256\n",
        "    encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "    decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    steps_per_epoch = 10000\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        epoch_loss = 0\n",
        "        epoch_acc = 0\n",
        "\n",
        "        with tqdm(total=steps_per_epoch, unit=\"step\", desc=f\"Epoch {epoch}\") as pbar:\n",
        "            for i in range(steps_per_epoch):\n",
        "                pair = random.choice(train_pairs_local)\n",
        "\n",
        "                input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "                target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "                loss, acc = train_step(input_tensor, target_tensor, encoder,\n",
        "                                  decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "                epoch_loss += loss\n",
        "                epoch_acc += acc\n",
        "\n",
        "                pbar.set_postfix({'acc': f'{epoch_acc/(i+1):.3f}', 'loss': f'{epoch_loss/(i+1):.3f}'})\n",
        "                pbar.update(1)\n",
        "\n",
        "\n",
        "            val_sample = random.sample(val_pairs_local, min(len(val_pairs_local), 100))\n",
        "\n",
        "            val_loss, val_acc = validate(encoder, decoder, val_sample, input_lang, output_lang, criterion)\n",
        "\n",
        "            pbar.set_postfix_str(\n",
        "                f\"acc: {epoch_acc/steps_per_epoch:.3f} - \"\n",
        "                f\"loss: {epoch_loss/steps_per_epoch:.3f} - \"\n",
        "                f\"val_acc: {val_acc:.3f} - \"\n",
        "                f\"val_loss: {val_loss:.3f}\"\n",
        "            )\n",
        "\n",
        "    return encoder, decoder, input_lang, output_lang"
      ],
      "metadata": {
        "id": "doo7gIzEe6pM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-SV'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405,
          "referenced_widgets": [
            "e463f042867248c1ad7d329e5c3f7643",
            "391eb25d6233410395467791a1287d0c",
            "c20a4054d2b145349952ddce0c087411",
            "6cc343281799421e928a3bb832f3682d",
            "f58a8640c0ac40caa24a3122cc1d05a0",
            "d7e519b4b4694559827e7cf033167b39",
            "3ffae624849247ce895abdf64414423e",
            "3b910e4e7b8c4a208cfa23238901dce7",
            "4b060c82daa8412f88109800d343a2bb",
            "2b2d89f94eea4b6290b7ea79920885d5",
            "84fab42bb1c744ad9ac22bb9be680057"
          ]
        },
        "id": "kvfVWxNmq-C-",
        "outputId": "e316784b-9a93-4c21-c5af-de74be81f89e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1:   0%|          | 0/10000 [00:00<?, ?step/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e463f042867248c1ad7d329e5c3f7643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-150605508.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_region\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'es-SV'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_en, model_de, lang_in, lang_out = train_specific_region(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtarget_region\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-613981606.py\u001b[0m in \u001b[0;36mtrain_specific_region\u001b[0;34m(region_name, n_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorFromSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 loss, acc = train_step(input_tensor, target_tensor, encoder,\n\u001b[0m\u001b[1;32m     50\u001b[0m                                   decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1163830533.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_tokens\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 )\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-PE'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "tSi42KNYvCAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-NI'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "R57iEIL7vCnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-DO'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "owqgchUBvG4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-EC'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "Uokwe742vM9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-PA'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "ZYv3OKExvQEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-PR'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "ykNz8Pl8vS-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-UY'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "mLZ79XmBvVJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-CO'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "eI9ztkEavXKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-CR'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "YvCOlmEnvZoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-VE'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "xxam64HGvbdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-AR'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "9p2CCqLnveay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-HN'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "l55-YCI0vgJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_region = 'es-CL'\n",
        "\n",
        "model_en, model_de, lang_in, lang_out = train_specific_region(\n",
        "    target_region,\n",
        "    n_epochs=5,\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "t6-RV9iIvnRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LjIW0F3neZCF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}